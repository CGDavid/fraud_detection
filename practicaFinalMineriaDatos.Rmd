El análisis exploratorio comienza investigando el significado y la naturaleza de 
las variables que nos proporciona el datase. Distinguiremos entre qué variables 
son relevantes y cuáles no para la clasificación de los datos.

```{r}
options(warn=-1)
library(data.table)
library(caTools)
library(smotefamily)
library(dplyr)
library(psych)
library(heatmaply)
library(ggplot2)
library(caret)
```

Leemos y guardamos el dataset. Echamos un vistazo a las columnas para ver qué tipo
de datos tenemos.

```{r}
df <- read.csv("creditcard.csv")
head(df, 10)
```

```{r}
print(paste("Tenemos un dataset con un total de", nrow(df), "datos"))
```

Podemos comprobar que todas las columnas menos Time y Amount están ofuscadas. Esto
es debido a que se trata de las componentes principales obtenidas de la aplicación
previa de la técnica de reducción de dimensionalidad PCA. Debido a esto, no podremos 
usar el sentido común en una primera instancia para elegir o descartar las variables
que utilizará nuestro modelo, ni tampoco para crear nuevas variables a partir de 
las originales.

Vamos a revisar la integridad de los datos. Empezaremos buscando campos vacíos.

```{r}
na_cols <- sapply(df, function(x) any(is.na(x) | x == '' ))
print(na_cols)
```

Comprobamos que no se haya colado ningún dato no numérico.

```{r}
nan_cols <- sapply(df, function(x) any(is.nan(x)))
print(nan_cols)
```

Todos los datos son correctos por lo que no hay que hacer un preprocesado
para limpiarlos.

Se revisan a continuación las características de cada variable:

```{r}
describe(select(df, -c(Time, Class)), fast=TRUE)
```

Se observa que todas las variables son numéricas, con valores decimales y valores tanto 
positivos menos negativos. Todas las variables (menos Amount) tienen media 0, ya
que los valores han sido previamente normalizados. A pesar de ello, se vé en las 
columnas "min" y "max" datos muy por encima del valor medio, con diferencias muy 
superiores a la desviación estándar.

Vamos a ver la distribución de los datos según la clase:

```{r}
table(df$Class)
```


```{r}
prop.table(table(df$Class))
```

Claramente hay una gran disparidad entre el número de datos de cada clase. Se trata
de un problema no balanceado, en el que si no aplicamos ninguna técnica para paliarlo
podemos llegar a obtener un clasificador que a pesar de dar muy buenos resultados
de accuracy, esté dando muy malos resultados a la hora de predecir transacciones
fraudulentas. Habrá que aplicar técnicas de oversampling o undersampling para solucionarlo.

A continuación, se visualiza mediante un boxplot los outliers de las diferentes variables:

```{r}
boxplot(select(df, -c(Time, Class, Amount)))
```

Efectivamente, se comprueba que hay outliers en varias variables. Vamos a ver si
podemos eliminarlos para evitar que afecten negativamente a nuestro modelo. Consideraremos
outlier cualquier dato que esté 1.5 * IQR por debajo o por encima de los cuantiles
inferior o superior respectivamente. Por no ser demasiado estrictos, usaremos el 
percentil 5 y 95:

```{r}
outliers <- function(data) {
  Q1 <- quantile(data, probs=.05)
  Q3 <- quantile(data, probs=.95)
  IQR = Q3-Q1

  Lower <- Q1 - 1.5 * IQR
  Upper <- Q3 + 1.5 * IQR 
  
  data < Lower | data > Upper
}

df_without_outliers <- df
df_variables <- select(df_without_outliers, -c(Time, Class, Amount))

for (col in names(df_variables)) {
  df_without_outliers <- df[!outliers(df[[col]]),]
}

boxplot(select(df_without_outliers, -c(Time, Class, Amount)))
```
```{r}
describe(select(df_without_outliers, -c(Time, Class)), fast=TRUE)
```

Tras la limpieza de datos, ya no existen valores mínimos y máximos tan alejados 
de la media. Vamos a comprobar si ha afectado demasiado a la clase minoritaria, 
ya que no queremos perder estos datos al ser tan escasos:

```{r}
prop.table(table(df_without_outliers$Class))
```

```{r}
prop.table(table(df$Class))
```
Como la proporción se mantiene casi intacta, es factible la eliminación. Se ha probado
con un rango más acotado de outliers pero se eliminan demasiadas instancias de la
clase minoritaria.

```{r}
df <- df_without_outliers
```

El dataset sigue siendo grande a pesar de la eliminación de outliers. Seguramente 
no todos los datos aporten información al modelo que usemos para predecir valores, 
por lo que vamos a intentar acortarlos. En primer lugar, vamos a comprobar qué 
correlaciones hay entre variables.

```{r}
heatmaply_cor(x = cor(df), xlab = "Features", ylab = "Features")
```

No hay fuertes correlaciones entre las variables, si acaso entre V20-amount,
V27-V28, V6-V8, V21-V22 o V2-V7. Igualmente no nos da demasiadas pistas sobre qué
variables afectan más o menos a la clasificación.

¿Es útil la variable time o podemos prescindir de ella? Para saberlo vamos a graficar
por separado las transacciones fraudulentas de las que no:

```{r}
non_fraudulent_data <- filter(df, Class == 0)

non_fraudulent_data %>% ggplot(aes(x = Time)) +
  geom_histogram(bins = 250) +
  labs(x = 'Time', y = 'Transactions')
```

Se interpreta una clara estacionalidad en las transacciones no fraudulentas. Comprobemos
las fraudulentas que son las que nos interesa poder clasificar:

```{r}
fraudulent_data <- filter(df, Class == 1)

fraudulent_data %>% ggplot(aes(x = Time)) +
  geom_histogram(bins = 100) +
  labs(x = 'Time', y = 'Transactions')
```

No se vé ningún patrón relevante que pueda dar información al modelo sobre cuándo
una transacción es fraudulenta, por lo que podemos prescindir de esta variable.

```{r}
df <- select(df, -c(Time))
```

¿Es relevante la variable Amount? Procedemos a graficarla también:

```{r}
ggplot(df, aes(x = factor(Class), y = Amount)) + 
        geom_boxplot() + 
        labs(x = 'Class', y = 'Amount')
```
Al parecer las transacciones fraudulentas se concentran en cantidades más pequeñas.
Tiene sentido ya que hay menos controles en transacciones con menor cantidad de 
dinero. Esta variable la mantendremos en el modelo ya que sí proporciona información útil.

Para poder usarla en el modelo tenemos que normalizarla o si no el modelo la sobreponderará
respecto al resto de variables. Normalizamos el dataframe a media 0 y desviación
estándar 1:

```{r}
df <- scale(df)
df <- df %>% mutate_at(c("Amount"), ~(scale(.) %>% as.vector))
```

## Creación del modelo

Se divide el dataset en 70% para el conjunto de datos de entrenamiento y el 30% 
para el de test:

```{r}
sample <- sample.split(df$Class, SplitRatio = 0.7)
train  <- subset(df, sample == TRUE)
test   <- subset(df, sample == FALSE)

X_train  <- select(train, -Class)
X_test   <- select(test, -Class)

Y_train <- select(train, Class)
Y_test <- select(test, Class)
```

### Ejemplo 1: Oversampling (Smote) + Regresión logística

Obtención de nuevas instancias de la clase minoritaria mediante BLSMOTE:

```{r}
new_train <- BLSMOTE(data.frame(X_train), data.frame(Y_train), K=5, C=5)
new_train$data$class <- as.integer(new_train$data$class)
table(new_train$data$class)
```
Entrenamiento del modelo y predicción de datos. Se muestra la matriz de confusión


```{r}
model <- glm(class~., data = new_train$data, family = binomial())
Y_test_pred <- round(predict(model, test, type = "response"))

confusionMatrix(
  factor(test$Class, levels = 0:1),
  factor(Y_test_pred, levels = 0:1)
)
```


```{r}
table(Y_test_pred)

```


```{r}

```

